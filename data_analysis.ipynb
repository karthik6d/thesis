{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(df, default_buffer_size):\n",
    "    columns = ['size', 'numberQueries', 'keyDistribution', 'valueDistribution',\n",
    "       'snappy_read_times', 'simd_read_times', 'rle_read_times',\n",
    "       'zlib_read_times', 'zstandard_read_times', 'uncompressed_read_times',\n",
    "       'snappy_load_times', 'simd_load_times', 'rle_load_times',\n",
    "       'zlib_load_times', 'zstandard_load_times', 'uncompressed_load_times',\n",
    "       'snappy_sizes', 'simd_sizes', 'rle_sizes', 'zlib_sizes',\n",
    "       'zstandard_sizes', 'uncompressed_sizes', 'readPercentage']\n",
    "    readPercentage = []\n",
    "    snappy_ratio = []\n",
    "    simd_ratio = []\n",
    "    rle_ratio = []\n",
    "    zlib_ratio = []\n",
    "    zstandard_ratio = []\n",
    "    default_buffer_sizes = []\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        if row % 2 == 0:\n",
    "            readPercentage.append(100)\n",
    "        else:\n",
    "            readPercentage.append(50)\n",
    "        \n",
    "        default_buffer_sizes.append(default_buffer_size)\n",
    "    \n",
    "    size = df['size']\n",
    "    numberQueries = df['numberQueries']\n",
    "    keyDistribution = df['keyDistribution']\n",
    "    valueDistribution = df['valueDistribution']\n",
    "    snappy_read_times = df['snappy_read_times']\n",
    "    simd_read_times = df['simd_read_times']\n",
    "    rle_read_times = df['rle_read_times']\n",
    "    zlib_read_times = df['zlib_read_times']\n",
    "    zstandard_read_times = df['zstandard_read_timesuncompressed_read_times']\n",
    "    uncompressed_read_times = df['snappy_load_times']\n",
    "    snappy_load_times = df['simd_load_times']\n",
    "    simd_load_times = df['rle_load_times']\n",
    "    rle_load_times = df['zlib_load_times']\n",
    "    zlib_load_times = df['zstandard_load_times']\n",
    "    zstandard_load_times = df['uncompressed_load_times']\n",
    "    uncompressed_load_times = df['snappy_sizes']\n",
    "    snappy_sizes = df['simd_sizes']\n",
    "    simd_sizes = df['rle_sizes']\n",
    "    rle_sizes = df['zlib_sizes']\n",
    "    zlib_sizes = df['zstandard_sizes']\n",
    "    zstandard_sizes = df['uncompressed_sizes']\n",
    "    uncompressed_sizes = df['readPercentage']\n",
    "    \n",
    "    data = zip(size, numberQueries, keyDistribution, valueDistribution, \n",
    "              snappy_read_times, simd_read_times, rle_read_times, zlib_read_times, zstandard_read_times, uncompressed_read_times,\n",
    "              snappy_load_times, simd_load_times, rle_load_times, zlib_load_times, zstandard_load_times, uncompressed_load_times,\n",
    "              snappy_sizes, simd_sizes, rle_sizes, zlib_sizes, zstandard_sizes, uncompressed_sizes, readPercentage)\n",
    "    \n",
    "    \n",
    "    new_df = pd.DataFrame(data, columns = columns)\n",
    "    \n",
    "    snappy_ratio = []\n",
    "    simd_ratio = []\n",
    "    rle_ratio = []\n",
    "    zlib_ratio = []\n",
    "    zstandard_ratio = []\n",
    "    default_buffer_sizes = []\n",
    "    \n",
    "    for row in range(len(new_df)):\n",
    "        default_buffer_sizes.append(default_buffer_size)\n",
    "        # Compute the ratios\n",
    "        uncompressed_size = new_df.iloc[row].uncompressed_sizes\n",
    "        \n",
    "        if uncompressed_size != 0:\n",
    "            sizes = new_df.iloc[row]\n",
    "            snappy_ratio.append(sizes['snappy_sizes'] / uncompressed_size)\n",
    "            simd_ratio.append(sizes['simd_sizes'] / uncompressed_size)\n",
    "            rle_ratio.append(sizes['rle_sizes'] / uncompressed_size)\n",
    "            zlib_ratio.append(sizes['zlib_sizes'] / uncompressed_size)\n",
    "            zstandard_ratio.append(sizes['zstandard_sizes'] / uncompressed_size)\n",
    "        else:\n",
    "            snappy_ratio.append(1)\n",
    "            simd_ratio.append(1)\n",
    "            rle_ratio.append(1)\n",
    "            zlib_ratio.append(1)\n",
    "            zstandard_ratio.append(1)\n",
    "    \n",
    "    columns = ['size', 'numberQueries', 'keyDistribution', 'valueDistribution',\n",
    "       'snappy_read_times', 'simd_read_times', 'rle_read_times',\n",
    "       'zlib_read_times', 'zstandard_read_times', 'uncompressed_read_times',\n",
    "       'snappy_load_times', 'simd_load_times', 'rle_load_times',\n",
    "       'zlib_load_times', 'zstandard_load_times', 'uncompressed_load_times',\n",
    "       'snappy_sizes', 'simd_sizes', 'rle_sizes', 'zlib_sizes',\n",
    "       'zstandard_sizes', 'uncompressed_sizes', 'readPercentage', \n",
    "        'snappy_ratios', 'simd_ratios', 'rle_ratios', 'zlib_ratios', 'zstandard_ratios', 'default_buffer_sizes']\n",
    "    data = zip(size, numberQueries, keyDistribution, valueDistribution, \n",
    "          snappy_read_times, simd_read_times, rle_read_times, zlib_read_times, zstandard_read_times, uncompressed_read_times,\n",
    "          snappy_load_times, simd_load_times, rle_load_times, zlib_load_times, zstandard_load_times, uncompressed_load_times,\n",
    "          snappy_sizes, simd_sizes, rle_sizes, zlib_sizes, zstandard_sizes, uncompressed_sizes, readPercentage, \n",
    "            snappy_ratio, simd_ratio, rle_ratio, zlib_ratio, zstandard_ratio, default_buffer_sizes)\n",
    "    \n",
    "    new_df = pd.DataFrame(data, columns = columns)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "def plot(df, keyDistribution, valueDistribution, readPercentage, mode):\n",
    "    columns = None\n",
    "    y_val = None\n",
    "    title = mode + ' Key Distribution: ' + str(keyDistribution) + ' Value Distribution: ' + str(valueDistribution) + ' Read Percentage: ' + str(readPercentage)\n",
    "    \n",
    "    if mode == 'read':\n",
    "        columns = ['snappy_read_times', 'simd_read_times', 'rle_read_times', 'zlib_read_times', \n",
    "                   'zstandard_read_times', 'uncompressed_read_times']\n",
    "        y_val = 'Latency (Seconds)'\n",
    "    elif mode == 'load':\n",
    "        columns = ['snappy_load_times', 'simd_load_times', 'rle_load_times', 'zlib_load_times', \n",
    "                   'zstandard_load_times', 'uncompressed_load_times']\n",
    "        y_val = 'Latency (Seconds)'\n",
    "    elif mode == 'ratio':\n",
    "        columns = ['snappy_ratios', 'simd_ratios', 'rle_ratios', 'zlib_ratios', \n",
    "                   'zstandard_ratios']\n",
    "        y_val = 'Ratio'\n",
    "    elif mode == 'sizes':\n",
    "        columns = ['snappy_sizes', 'simd_sizes', 'rle_sizes', 'zlib_sizes',\n",
    "                  'zstandard_sizes', 'uncompressed_sizes']\n",
    "        y_val = 'Latency (Seconds)'\n",
    "    \n",
    "    \n",
    "    filtered_df = df[(df['keyDistribution'] == keyDistribution) & (df['valueDistribution'] == valueDistribution) & \n",
    "                     (df['readPercentage'] == readPercentage)]\n",
    "    \n",
    "    plot_data = defaultdict(None)\n",
    "    for col in columns:\n",
    "        plot_data[col] = list(filtered_df[col])\n",
    "    \n",
    "    plot_df = pd.DataFrame(plot_data, index=list(filtered_df['size']))\n",
    "    lines = plot_df.plot.line(title=title)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Machine Learning --> can we predict compression ratio R based on the keyDistribution, valueDistribution, size\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def create_ml_data(df, compression_type):\n",
    "    columns = ['keyDistribution', 'valueDistribution', 'size', 'numberQueries']\n",
    "    X = df[columns].to_numpy()\n",
    "    y = df[[compression_type]].to_numpy()\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def crossFoldValidation(X, y, model):\n",
    "    cv_results = cross_validate(model, X, y, cv=5)\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    return LinearRegression().fit(X, y)\n",
    "\n",
    "def random_forest(X, y):\n",
    "    return RandomForestRegressor(max_depth=10, random_state=0).fit(X, y)\n",
    "\n",
    "def mlp_regressor(X, y):\n",
    "    return MLPRegressor(random_state=1, max_iter=500).fit(X, y)\n",
    "\n",
    "def run_ml(df, compression_scheme):\n",
    "    X, y = create_ml_data(df, compression_scheme)\n",
    "    linreg = linear_regression(X, y)\n",
    "    rf = random_forest(X, y)\n",
    "    mlp = mlp_regressor(X, y)\n",
    "    \n",
    "    print(\"Linear Regression CV Scores: \", crossFoldValidation(X, y, linreg)['test_score'])\n",
    "    print(\"Random Forest CV Scores: \", crossFoldValidation(X, y, rf))\n",
    "    print(\"MLP Regressor CV Scores: \", crossFoldValidation(X, y, mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '04022021230051.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-28fa9927d9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrun_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuc72\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'snappy_ratios'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-28fa9927d9e6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnuc71\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'04022021230051.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnuc72\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'06022021024240.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnuc71\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuc71\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16384\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '04022021230051.csv'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    nuc71 = pd.read_csv('04022021230051.csv', index_col=False)\n",
    "    nuc72 = pd.read_csv('06022021024240.csv', index_col=False)\n",
    "    \n",
    "    nuc71 = fix_data(nuc71, 16384)\n",
    "    nuc72 = fix_data(nuc72, 32768*2)\n",
    "    \n",
    "    # Plots Go Here\n",
    "    plot(nuc72, 1, 1, 100, 'read')\n",
    "    \n",
    "    #ML Go Here\n",
    "    run_ml(nuc72, 'snappy_ratios')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
